{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/conda_envs/mmd3/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mmcv\n",
    "import mmengine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.registry import RUNNERS\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config 파일 로드 및 수정\n",
    "cfg = Config.fromfile('./configs/trash/co_dino_5scale_r50_8xb2_1x_coco.py')\n",
    "\n",
    "checkpoint_path = './work_dirs/co_dino_5scale_r50_8xb2_1x_coco/epoch_12.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_conv.bias - torch.Size([256]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_cls.weight - torch.Size([9, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_cls.bias - torch.Size([9]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_reg.weight - torch.Size([36, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_reg.bias - torch.Size([36]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/mmdetection/projects/CO-DETR/codetr/transformer.py:1325: UserWarning: If you want to reduce GPU memory usage,                               please install fairscale by executing the                               following command: pip install fairscale.\n",
      "  warnings.warn('If you want to reduce GPU memory usage, \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_cls.weight - torch.Size([11, 1024]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_cls.bias - torch.Size([11]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_reg.weight - torch.Size([40, 1024]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_reg.bias - torch.Size([40]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_cls.weight - torch.Size([10, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_cls.bias - torch.Size([10]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_reg.weight - torch.Size([4, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_reg.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_centerness.weight - torch.Size([1, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_centerness.bias - torch.Size([1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "10/22 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.5.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "Loads checkpoint by local backend from path: ./work_dirs/co_dino_5scale_r50_8xb2_1x_coco/epoch_12.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/mmdetection/mmdet/models/dense_heads/anchor_head.py:108: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "model = init_detector(cfg, checkpoint_path, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/conda_envs/mmd3/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file has been created!\n"
     ]
    }
   ],
   "source": [
    "root = '/data/ephemeral/home/dataset/'\n",
    "\n",
    "coco = COCO(os.path.join(root, 'test.json'))\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "for img_id in img_ids:\n",
    "    # 이미지 정보 가져오기\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_path = os.path.join(root, img_info['file_name'])\n",
    "    \n",
    "    # 추론 수행\n",
    "    result = inference_detector(model, img_path)\n",
    "    \n",
    "    # 결과 문자열 생성\n",
    "    prediction_string = ''\n",
    "    bboxes = result.pred_instances.bboxes.cpu()\n",
    "    scores = result.pred_instances.scores.cpu()\n",
    "    labels = result.pred_instances.labels.cpu()\n",
    "    for i in range(len(bboxes)):\n",
    "        label = labels[i].item()\n",
    "        score = scores[i].item()\n",
    "        box = bboxes[i]\n",
    "        prediction_string += f\"{label} {score:.6f} {box[0].item():.6f} {box[1].item():.6f} {box[2].item():.6f} {box[3].item():.6f} \"\n",
    " \n",
    "    \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(img_info['file_name'])\n",
    "\n",
    "# submission 파일 생성\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv('submission.csv', index=None)\n",
    "print(\"Submission file has been created!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmd3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
